{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7586520-322d-4da6-bde7-26715e3b21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "import pickle\n",
    "import logging\n",
    "import traceback\n",
    "from time import sleep, time\n",
    "from datetime import datetime\n",
    "from openai import OpenAIError\n",
    "from data.serialize import SerializerSettings\n",
    "from models.utils import grid_iter\n",
    "from models.promptcast import get_promptcast_predictions_data\n",
    "from models.llmtime import get_llmtime_predictions_data\n",
    "from models.validation_likelihood_tuning import get_autotuned_predictions_data\n",
    "\n",
    "# Set up API key and environment\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY', \"\")\n",
    "\n",
    "def create_logger(filename: str, name: str = None):\n",
    "    logger = logging.getLogger(name)\n",
    "\n",
    "   # Set the overall logging level\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    if len(logger.handlers) == 0:\n",
    "        \n",
    "        # Create handlers\n",
    "        file_handler = logging.FileHandler(filename)\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        \n",
    "        # Set logging levels for handlers\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        stream_handler.setLevel(logging.INFO)\n",
    "        \n",
    "        # Create formatters and add them to handlers\n",
    "        formatter = logging.Formatter('%(asctime)s | %(filename)s | %(levelname)s | %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        stream_handler.setFormatter(formatter)\n",
    "        \n",
    "        # Add handlers to the logger\n",
    "        logger.addHandler(file_handler)\n",
    "        logger.addHandler(stream_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def run_analysis(asset, w, logger, temperature=0.7, model_name='gpt-4o'):\n",
    "    \"\"\"\n",
    "    Run LLM-based time series analysis with configurable parameters\n",
    "    \n",
    "    Args:\n",
    "        asset (str): Asset name for the Excel file\n",
    "        w (int): Window size\n",
    "        logger (logging.Logger): A logger for file persistence\n",
    "        temperature (float): Temperature parameter for the model (0.0 to 1.0)\n",
    "        model_name (str): Model name (e.g., 'gpt-4o', 'gpt-3.5-turbo', etc.)\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    n = 128\n",
    "    steps = 8\n",
    "    window = w + steps\n",
    "    max_retries = 50\n",
    "    save_interval = 1\n",
    "\n",
    "    # Define model hyperparameters\n",
    "    base_hypers = dict(\n",
    "        temp=temperature,\n",
    "        alpha=0.95,\n",
    "        beta=0.3,\n",
    "        basic=False,\n",
    "        settings=SerializerSettings(base=10, prec=2, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\n",
    "    )\n",
    "\n",
    "    # Define available models and their configurations\n",
    "    model_hypers = {\n",
    "        f'LLMTime {model_name}': {'model': model_name, **base_hypers}\n",
    "    }\n",
    "\n",
    "    model_predict_fns = {\n",
    "        f'LLMTime {model_name}': get_llmtime_predictions_data\n",
    "    }\n",
    "\n",
    "    model_names = list(model_predict_fns.keys())\n",
    "    current_model_key = f'LLMTime {model_name}'\n",
    "\n",
    "    # Create unique filenames based on parameters\n",
    "    results_filename = f\"rolling_results_{asset}_w{w}_temp{temperature}_{model_name.replace('-', '_')}.pkl\"\n",
    "    time_log_filename = f\"time_log_{asset}_w{w}_temp{temperature}_{model_name.replace('-', '_')}.pkl\"\n",
    "    \n",
    "    # Delete existing pkl files at the beginning\n",
    "    if os.path.exists(results_filename):\n",
    "        os.remove(results_filename)\n",
    "    if os.path.exists(time_log_filename):\n",
    "        os.remove(time_log_filename)\n",
    "\n",
    "    # Load the DataFrame\n",
    "    df = pd.read_excel(f\"datasets/{asset}.xlsx\")\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    df = df[df['Date'] >= \"2021-10-01\"]\n",
    "    df = df.set_index('Date')\n",
    "    df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df = df[['Log_Return']]\n",
    "    df = df.dropna()\n",
    "\n",
    "    def save_results(results, filename=results_filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(results, f)\n",
    "\n",
    "    def load_results(filename=results_filename):\n",
    "        try:\n",
    "            with open(filename, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            return []\n",
    "\n",
    "    def save_time_log(start_time, filename=time_log_filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(start_time, f)\n",
    "\n",
    "    def load_time_log(filename=time_log_filename):\n",
    "        try:\n",
    "            with open(filename, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "\n",
    "    def get_dataset_DP(df):\n",
    "        series = df.iloc[:, 0]\n",
    "        return series\n",
    "\n",
    "    def get_datasets_DP(ds, ds_name, testfrac=0.2, predict_steps=steps):\n",
    "        series = get_dataset_DP(ds)\n",
    "        splitpoint = len(series) - predict_steps if predict_steps is not None else int(len(series) * (1 - testfrac))\n",
    "        train = series.iloc[:splitpoint]\n",
    "        test = series.iloc[splitpoint:]\n",
    "        return {ds_name: (train, test)}\n",
    "\n",
    "    # Main processing function\n",
    "    def rolling_window_datasets(df, window_length=window, predict_steps=steps):\n",
    "        rolling_results = load_results()\n",
    "        start_index = len(rolling_results)\n",
    "        total_iterations = len(df) - window_length\n",
    "\n",
    "        for start in range(start_index, total_iterations):\n",
    "            try:\n",
    "                logger.info(f\"Processing window starting at index {start} of {total_iterations} (Asset: {asset}, Window: {w}, Temp: {temperature}, Model: {model_name})\")\n",
    "                end = start + window_length\n",
    "                ds = df.iloc[start:end]\n",
    "                datasets = get_datasets_DP(ds, 'ds', predict_steps=steps)\n",
    "                ds_name = 'ds'\n",
    "                train, test = datasets[ds_name]\n",
    "\n",
    "                out = {}\n",
    "                dates = ds.index[-1]\n",
    "                last_value = ds.iloc[-1]\n",
    "\n",
    "                for model in model_names:\n",
    "                    random_seed = np.random.randint(0, 100000)\n",
    "                    model_hypers[model].update({'dataset_name': ds_name, 'random_seed': random_seed})\n",
    "                    hypers = list(grid_iter(model_hypers[model]))\n",
    "\n",
    "                    retries = 0\n",
    "                    while retries < max_retries:\n",
    "                        try:\n",
    "                            pred_dict = get_autotuned_predictions_data(train, test, hypers, n, model_predict_fns[model], verbose=False, parallel=True)\n",
    "                            out[model] = pred_dict['samples']\n",
    "                            break\n",
    "                        except OpenAIError as e:\n",
    "                            retries += 1\n",
    "                            logger.error(f\"API error (attempt {retries}/{max_retries}): {e}\")\n",
    "                            sleep(1)\n",
    "                            if retries == max_retries:\n",
    "                                logger.error(f\"Failed to get predictions for {model} after {max_retries} retries.\")\n",
    "                                out[model] = np.nan\n",
    "\n",
    "                rolling_results.append((dates, out, last_value))\n",
    "\n",
    "                if (start - start_index + 1) % save_interval == 0:\n",
    "                    logger.info(f\"Saving intermediate results at index {start}\")\n",
    "                    save_results(rolling_results)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error at index {start}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                save_results(rolling_results)\n",
    "                raise e\n",
    "\n",
    "        save_results(rolling_results)\n",
    "        return rolling_results\n",
    "\n",
    "    # Main loop to handle restarting from the last save\n",
    "    while True:\n",
    "        try:\n",
    "            start_time = time()\n",
    "            save_time_log(start_time)\n",
    "            rolling_results = rolling_window_datasets(df)\n",
    "            end_time = time()\n",
    "            logger.info(f\"Processing time: {end_time - start_time} seconds\")\n",
    "\n",
    "            # Clean up temporary files\n",
    "            if os.path.exists(results_filename):\n",
    "                os.remove(results_filename)\n",
    "            if os.path.exists(time_log_filename):\n",
    "                os.remove(time_log_filename)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logger.error(\"An error occurred. Restarting from last save...\")\n",
    "            sleep(2)\n",
    "\n",
    "    # Post-processing and output\n",
    "    prediction_dict = rolling_results\n",
    "    m = n * steps\n",
    "    \n",
    "    # Updated column names to include metadata\n",
    "    prediction_columns = [f'Log Return {i+1}' for i in range(m)]\n",
    "    column_names = ['Date', 'Asset', 'Model', 'Temperature', 'Window'] + prediction_columns\n",
    "    output = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    # Loop through each item in the predictions dictionary\n",
    "    for item in prediction_dict:\n",
    "        date = item[0]  # Extract the date from DatetimeIndex\n",
    "        data_matrix = item[1].get(current_model_key, None)  # Extract the DataFrame\n",
    "\n",
    "        if data_matrix is not None and isinstance(data_matrix, pd.DataFrame):\n",
    "            # Flatten the DataFrame to a single list\n",
    "            flat_list = data_matrix.values.flatten().tolist()\n",
    "            \n",
    "            # Create row with metadata and predictions\n",
    "            row_data = [date, asset, model_name, temperature, w] + flat_list\n",
    "            \n",
    "            # Append this list as a row in the output DataFrame\n",
    "            output.loc[len(output)] = row_data\n",
    "        else:\n",
    "            print(f\"Warning: Expected DataFrame at {date} but got {type(data_matrix)}\")\n",
    "\n",
    "    # Write DataFrame to Excel with updated filename\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    output_filename = f\"{current_date}_{asset}_LLMTime_{model_name.replace('-', '_')}_w{w}_temp{temperature}.xlsx\"\n",
    "    output.to_excel(output_filename, index=False)\n",
    "    \n",
    "    logger.info(f\"Results saved to: {output_filename}\")\n",
    "    return output\n",
    "\n",
    "def run_temperature_sweep(asset, window_sizes, logger, models=['gpt-4o'], temp_range=(0.0, 1.0, 0.1)):\n",
    "    \"\"\"\n",
    "    Run analysis across multiple temperature values, models, and window sizes\n",
    "    \n",
    "    Args:\n",
    "        asset (str): Asset name\n",
    "        window_sizes (list): List of window sizes to test\n",
    "        logger (logging.Logger): Logger for file persistence\n",
    "        models (list): List of model names to test\n",
    "        temp_range (tuple): (start, stop, step) for temperature range\n",
    "    \"\"\"\n",
    "    temperatures = np.arange(temp_range[0], temp_range[1] + temp_range[2], temp_range[2])\n",
    "    temperatures = np.round(temperatures, 1)  # Round to avoid floating point issues\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for model_name in models:\n",
    "        for w in window_sizes:\n",
    "            for temp in temperatures:\n",
    "                logger.info(f\"Running analysis: Asset={asset}, Model={model_name}, Window={w}, Temperature={temp}\")\n",
    "                \n",
    "                try:\n",
    "                    result = run_analysis(asset, w, logger=logger, temperature=temp, model_name=model_name)\n",
    "                    all_results.append(result)\n",
    "                    \n",
    "                    # Optional: save individual results\n",
    "                    logger.info(f\"Completed: {asset}, {model_name}, w={w}, temp={temp}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed for {asset}, {model_name}, w={w}, temp={temp}: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    # Combine all results into a single DataFrame\n",
    "    if all_results:\n",
    "        combined_results = pd.concat(all_results, ignore_index=True)\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        combined_filename = f\"{current_date}_{asset}_combined_results.xlsx\"\n",
    "        combined_results.to_excel(combined_filename, index=False)\n",
    "        logger.info(f\"All results combined and saved to: {combined_filename}\")\n",
    "        return combined_results\n",
    "    else:\n",
    "        print(\"No results to combine.\")\n",
    "        return None\n",
    "\n",
    "# Multi-asset, multi-model grid search function\n",
    "def multi_asset_multi_model_grid_search(assets, models=['gpt-4o'], window_sizes=None, temperatures=None):\n",
    "    \"\"\"\n",
    "    Run complete grid search over multiple assets, models, temperatures and window sizes\n",
    "    \n",
    "    Args:\n",
    "        assets (list): List of asset names (e.g., ['AAPL', 'GOOGL', 'MSFT'])\n",
    "        models (list): List of model names (e.g., ['gpt-4o', 'gpt-3.5-turbo', 'gpt-4'])\n",
    "        window_sizes (list): Window sizes (default: [30, 45, 60, 90, 120, 150])\n",
    "        temperatures (list): Temperature values (default: [0.0, 0.1, ..., 1.0])\n",
    "    \"\"\"\n",
    "    if window_sizes is None:\n",
    "        window_sizes = [45]\n",
    "    if temperatures is None:\n",
    "        temperatures = [round(temp * 0.1, 1) for temp in range(11)]  # [0.0, 0.1, 0.2, ..., 1.0]\n",
    "    logger = create_logger(\"gpt4turbo_0.9_1_temp.log\", \"temperature_sweep\")\n",
    "    \n",
    "    total_runs = len(assets) * len(models) * len(window_sizes) * len(temperatures)\n",
    "    current_run = 0\n",
    "    \n",
    "    logger.info(f\"ðŸš€ Starting Multi-Asset Multi-Model Grid Search\")\n",
    "    logger.info(f\"Assets: {assets}\")\n",
    "    logger.info(f\"Models: {models}\")\n",
    "    logger.info(f\"Window Sizes: {window_sizes}\")\n",
    "    logger.info(f\"Temperatures: {temperatures}\")\n",
    "    logger.info(f\"Total Runs: {total_runs}\")\n",
    "    \n",
    "    all_results = []\n",
    "    failed_runs = []\n",
    "    \n",
    "    for asset in assets:\n",
    "        logger.info(f\"ðŸ’° Processing Asset: {asset}\")\n",
    "        \n",
    "        asset_results = []\n",
    "        \n",
    "        for model_name in models:\n",
    "            logger.info(f\"ðŸ¤– Asset: {asset} | Model: {model_name}\")\n",
    "            \n",
    "            model_results = []\n",
    "            \n",
    "            for window_size in window_sizes:\n",
    "                logger.info(f\"ðŸ“Š {asset} | {model_name} | Window: {window_size}\")\n",
    "                \n",
    "                for temp in temperatures:\n",
    "                    current_run += 1\n",
    "                    progress = (current_run / total_runs) * 100\n",
    "                    \n",
    "                    logger.info(f\"[{current_run}/{total_runs}] ({progress:.1f}%) - {asset}|{model_name}|W:{window_size}|T:{temp}\")\n",
    "                    \n",
    "                    try:\n",
    "                        result = run_analysis(asset, window_size, logger=logger, temperature=temp, model_name=model_name)\n",
    "                        all_results.append(result)\n",
    "                        asset_results.append(result)\n",
    "                        model_results.append(result)\n",
    "                        logger.info(f\"âœ… SUCCESS\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        failed_runs.append((asset, model_name, window_size, temp, str(e)))\n",
    "                        logger.error(f\"âŒ FAILED - Error: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            # Save individual model results for this asset\n",
    "            if model_results:\n",
    "                model_combined = pd.concat(model_results, ignore_index=True)\n",
    "                current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "                model_filename = f\"{current_date}_{asset}_{model_name.replace('-', '_')}_COMPLETE_GRID.xlsx\"\n",
    "                model_combined.to_excel(model_filename, index=False)\n",
    "                logger.error(f\"ðŸ’¾ {asset}-{model_name} results saved to: {model_filename}\")\n",
    "        \n",
    "        # Save individual asset results (all models)\n",
    "        if asset_results:\n",
    "            asset_combined = pd.concat(asset_results, ignore_index=True)\n",
    "            current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "            asset_filename = f\"{current_date}_{asset}_ALL_MODELS_COMPLETE_GRID.xlsx\"\n",
    "            asset_combined.to_excel(asset_filename, index=False)\n",
    "            logger.info(f\"ðŸ’¾ Asset {asset} (all models) results saved to: {asset_filename}\")\n",
    "    \n",
    "    # Combine all results across all assets and models\n",
    "    if all_results:\n",
    "        combined_results = pd.concat(all_results, ignore_index=True)\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # Create master file with all assets and models\n",
    "        master_filename = f\"{current_date}_ALL_ASSETS_ALL_MODELS_MASTER_GRID.xlsx\"\n",
    "        combined_results.to_excel(master_filename, index=False)\n",
    "        \n",
    "        logger.info(f\"ðŸŽ‰ MULTI-ASSET MULTI-MODEL GRID SEARCH COMPLETED!\")\n",
    "        logger.info(f\"ðŸ“ Master file saved to: {master_filename}\")\n",
    "        \n",
    "        # Print detailed summary\n",
    "        logger.info(f\"\\nðŸ“ˆ FINAL SUMMARY:\")\n",
    "        logger.info(f\"- Assets: {len(assets)} ({assets})\")\n",
    "        logger.info(f\"- Models: {len(models)} ({models})\")\n",
    "        logger.info(f\"- Window Sizes: {len(window_sizes)} ({window_sizes})\")\n",
    "        logger.info(f\"- Temperatures: {len(temperatures)} ({min(temperatures)} to {max(temperatures)})\")\n",
    "        logger.info(f\"- Total Attempted: {total_runs}\")\n",
    "        logger.info(f\"- Successful Runs: {len(all_results)}\")\n",
    "        logger.info(f\"- Failed Runs: {len(failed_runs)}\")\n",
    "        logger.info(f\"- Success Rate: {(len(all_results)/total_runs)*100:.1f}%\")\n",
    "        logger.info(f\"- Total Predictions: {len(combined_results)}\")\n",
    "        \n",
    "        # Summary by asset and model\n",
    "        logger.info(f\"ðŸ“Š RESULTS BY ASSET & MODEL:\")\n",
    "        for asset in assets:\n",
    "            logger.info(f\"  {asset}:\")\n",
    "            for model in models:\n",
    "                asset_model_data = combined_results[\n",
    "                    (combined_results['Asset'] == asset) & \n",
    "                    (combined_results['Model'] == model)\n",
    "                ]\n",
    "                expected_runs = len(window_sizes) * len(temperatures)\n",
    "                actual_runs = len(asset_model_data)\n",
    "                logger.info(f\"    {model}: {actual_runs}/{expected_runs} runs ({(actual_runs/expected_runs)*100:.1f}%)\")\n",
    "        \n",
    "        if failed_runs:\n",
    "            logger.error(f\"\\nâŒ Failed Runs Details:\")\n",
    "            for asset, model, window_size, temp, error in failed_runs:\n",
    "                logger.error(f\"   - {asset}|{model}|W:{window_size}|T:{temp} - {error}\")\n",
    "        \n",
    "        return combined_results\n",
    "    else:\n",
    "        logger.error(\"âŒ No successful results to combine.\")\n",
    "        return None\n",
    "\n",
    "# Multi-asset grid search function (updated to use single model)\n",
    "def multi_asset_grid_search(assets, model_name='gpt-4o'):\n",
    "    \"\"\"\n",
    "    Run complete grid search over multiple assets, all temperatures and window sizes (single model)\n",
    "    \n",
    "    Args:\n",
    "        assets (list): List of asset names (e.g., ['AAPL', 'GOOGL', 'MSFT'])\n",
    "        model_name (str): Model name (default: 'gpt-4o')\n",
    "    \"\"\"\n",
    "    return multi_asset_multi_model_grid_search(assets, models=[model_name])\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Define your assets and models\n",
    "    assets = ['SP500']\n",
    "    models = ['gpt-4-turbo']  # Add your desired models\n",
    "    \n",
    "    # Option 1: Multi-asset, multi-model grid search (FULL GRID)\n",
    "    # For 5 assets Ã— 3 models Ã— 6 windows Ã— 11 temps = 990 total runs\n",
    "    multi_asset_multi_model_grid_search(assets=assets, models=models, temperatures=[1.])\n",
    "    \n",
    "    # Option 2: Multi-asset, single model (original function)\n",
    "    # For 5 assets Ã— 6 windows Ã— 11 temps = 330 total runs\n",
    "    # multi_asset_grid_search(assets=assets, model_name='gpt-4o')\n",
    "    \n",
    "    # Option 3: Custom parameters\n",
    "    # multi_asset_multi_model_grid_search(\n",
    "    #     assets=['AAPL', 'GOOGL'], \n",
    "    #     models=['gpt-4o', 'gpt-3.5-turbo'],\n",
    "    #     window_sizes=[30, 60, 90],\n",
    "    #     temperatures=[0.0, 0.5, 1.0]\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1692551-c359-428e-b994-f613ca4d16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"rolling_results_SP500_w45_temp0.1_gpt_4_turbo.pkl\", \"rb\") as f:\n",
    "    current_temp0 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a5812d-b833-4578-ba02-fb462a104231",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_temp0[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfb7a4-ba57-4f5f-96e8-36ee72b0def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86738f36-1fa2-4506-8e2e-77220a6b6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(asset: str):\n",
    "    df = pd.read_excel(f\"datasets/{asset}.xlsx\")\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    df = df[df['Date'] >= \"2021-10-01\"]\n",
    "    df = df.set_index('Date')\n",
    "    df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df = df[['Log_Return']]\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52bc5c-0129-4d3a-8eb0-137265c8112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500 = read_dataset(\"SP500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89d934-7cc3-4ba8-8080-b6acad15bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500.iloc[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ee551-2ab3-4547-bbb1-bb1ae8a7b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.serialize import serialize_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1964637-ec50-4830-b37b-cc9995cea97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_arr(SP500[\"Log_Return\"].values * 10_000, SerializerSettings(base=10, prec=2, signed=True, time_sep=', ', bit_sep='', minus_sign='-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893b05f-81be-4393-b146-567e7baf8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenier = tiktoken.get_encoding(\"cl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20f0ce-5b94-48da-a81c-13f78f02e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\", \".join(map(str, range(100, 250)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
